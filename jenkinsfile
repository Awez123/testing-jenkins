pipeline {
    agent {
        kubernetes {
            yaml """
apiVersion: v1
kind: Pod
metadata:
  labels:
    purpose: eks-deploy
spec:
  serviceAccountName: jenkins # This is the K8s Service Account for the Jenkins agent itself, not for EKS deployment
  containers:
  - name: aws-tools
    image: jerinpaul/awscli-helm-kubectl:latest
    command: ['cat']
    tty: true
    resources:
      limits:
        memory: "1Gi"
        cpu: "1000m"
      requests:
        memory: "512Mi"
        cpu: "500m"
  restartPolicy: Never
"""
            defaultContainer 'aws-tools'
        }
    }

    environment {
        AWS_REGION = 'ap-south-1'
        CLUSTER_NAME = 'hh-stg-eks'
        NGINX_CHART_PATH = './nginx'
        NGINX_NAMESPACE = 'nginx'
        KUBECONFIG_PATH = '/workspace/kubeconfig'
        # Define a temporary AWS_PROFILE for the jenkinsuser credentials
        AWS_PROFILE_NAME = 'jenkins-pipeline-profile'
    }

    stages {
        stage('Clone Repo') {
            steps {
                git 'https://github.com/Awez123/testing-jenkins.git'
            }
        }

        stage('Configure AWS & kubeconfig') {
            steps {
                withCredentials([[$class: 'AmazonWebServicesCredentialsBinding', credentialsId: 'jenkinsuser']]) {
                    sh '''
                        echo "🔐 Authenticating with AWS..."
                        # Verify the AWS environment variables are set by withCredentials
                        echo "DEBUG: AWS_ACCESS_KEY_ID is set: ${AWS_ACCESS_KEY_ID:+true}"
                        echo "DEBUG: AWS_SECRET_ACCESS_KEY is set: ${AWS_SECRET_ACCESS_KEY:+true}"

                        # Configure a temporary AWS CLI profile using the credentials from withCredentials
                        # This ensures 'aws eks update-kubeconfig' uses these specific credentials
                        mkdir -p ~/.aws
                        cat > ~/.aws/credentials <<EOF
[${AWS_PROFILE_NAME}]
aws_access_key_id = ${AWS_ACCESS_KEY_ID}
aws_secret_access_key = ${AWS_SECRET_ACCESS_KEY}
EOF
                        cat > ~/.aws/config <<EOF
[profile ${AWS_PROFILE_NAME}]
region = ${AWS_REGION}
EOF

                        # Set AWS_PROFILE for subsequent aws CLI commands
                        export AWS_PROFILE=${AWS_PROFILE_NAME}

                        aws sts get-caller-identity

                        echo "📋 Listing EKS clusters..."
                        aws eks list-clusters --region ${AWS_REGION}

                        echo "🔧 Updating kubeconfig for ${CLUSTER_NAME} using profile ${AWS_PROFILE_NAME}..."
                        # Explicitly use the profile when updating kubeconfig
                        aws eks update-kubeconfig --region ${AWS_REGION} \
                            --name ${CLUSTER_NAME} \
                            --kubeconfig ${KUBECONFIG_PATH} \
                            --profile ${AWS_PROFILE_NAME}

                        echo "DEBUG: Contents of generated KUBECONFIG:"
                        cat ${KUBECONFIG_PATH}

                        echo "✅ Testing Kubeconfig..."
                        export KUBECONFIG=${KUBECONFIG_PATH}
                        
                        echo "DEBUG: Current Kubernetes context:"
                        kubectl config current-context

                        echo "DEBUG: Get nodes:"
                        kubectl get nodes

                        echo "DEBUG: Who am I according to Kubernetes (should be jenkins-eks-deployment-user):"
                        kubectl auth can-i list secrets --namespace ${NGINX_NAMESPACE}
                        kubectl auth can-i '*' '*' --all-namespaces # Check full access

                        echo "DEBUG: Get caller identity from AWS again (should still be jenkins-eks-cluster-deployment-user):"
                        aws sts get-caller-identity
                    '''
                }
            }
        }

        stage('Deploy NGINX Helm Chart') {
            steps {
                sh '''
                    echo "🚀 Deploying NGINX chart..."
                    export KUBECONFIG=${KUBECONFIG_PATH}

                    # Add more debug info right before helm
                    echo "DEBUG: KUBECONFIG path before helm: ${KUBECONFIG}"
                    echo "DEBUG: Current context before helm:"
                    kubectl config current-context
                    echo "DEBUG: Auth check before helm:"
                    kubectl auth can-i list secrets --namespace ${NGINX_NAMESPACE}

                    # Use --kube-context explicitly, and ensure the profile is still active
                    # The KUBECONFIG generated by 'aws eks update-kubeconfig --profile' should embed the profile usage
                    helm upgrade --install my-nginx ./nginx --namespace ${NGINX_NAMESPACE} --create-namespace --wait \
                        --kube-context arn:aws:eks:ap-south-1:650576187890:cluster/hh-stg-eks

                    echo "✅ NGINX deployed successfully!"
                    kubectl get all -n ${NGINX_NAMESPACE}
                '''
            }
        }
    }

    post {
        always {
            echo currentBuild.result == 'SUCCESS' ? "✅ Pipeline completed successfully!" : "❌ Pipeline failed. Check logs."
        }
    }
}
